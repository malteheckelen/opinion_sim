install.packages("tidyverse", dependencies=TRUE) # "Saubere" Datenverarbeitung in R (dazu später mehr)
install.packages("tidytext", dependencies=TRUE) # "Saubere" Textdatenverarbeitung in R
install.packages("tm", dependencies=TRUE) # "text mining", ein Standardpaket für Textdatenverarbeitung
install.packages("quanteda", dependencies=TRUE) # ebenfalls Textdatenverarbeitung
install.packages("stringr", dependencies=TRUE) # bietet Stringmanipulation ähnlich zu Python
install.packages("stringi", dependencies=TRUE) # ebenfalls (ältere Version mit besonderen Funktionen)
install.packages("SnowballC", dependencies=TRUE) # Stemming und weitere Tools aus dem NLP
install.packages("DT")
#knitr::opts_chunk$set(echo = TRUE)
library(knitr)
opts_knit$set(root.dir = "~/GitHub/DH_grundlagen/sitzungen/11/Rdaten")
library(DT)
result <- stylo(gui=TRUE, corpus.dir="Literatur_Zeit")
#knitr::opts_chunk$set(echo = TRUE)
library(knitr)
opts_knit$set(root.dir = "~/GitHub/DH_grundlagen/sitzungen/11/Rdaten")
library(DT)
dtm_absolute <-text_df %>%
unnest_tokens(word, text, token="words", to_lower = TRUE) %>% # wieder in Token auf "Wort"-Basis aufsplitten und alles klein setzen
group_by(id, word) %>% # nach Werk-ID und Wort gruppieren
mutate(count = n()) %>% # dank Gruppierung wird jedes Wort pro Werk gezählt und in "count"-Variable geschrieben
select(word, id, count) %>% # wir brauchen nur noch diese Variablen
cast_sparse(id, word, count) %>%
as.matrix()
load("~/GitHub/data/DH_grundlagen/stylo_uebung.RData")
#knitr::opts_chunk$set(echo = TRUE)
library(knitr)
opts_knit$set(root.dir = "~/GitHub/DH_grundlagen/sitzungen/11/Rdaten")
library(DT)
dtm_absolute <-text_df %>%
unnest_tokens(word, text, token="words", to_lower = TRUE) %>% # wieder in Token auf "Wort"-Basis aufsplitten und alles klein setzen
group_by(id, word) %>% # nach Werk-ID und Wort gruppieren
mutate(count = n()) %>% # dank Gruppierung wird jedes Wort pro Werk gezählt und in "count"-Variable geschrieben
select(word, id, count) %>% # wir brauchen nur noch diese Variablen
cast_sparse(id, word, count) %>%
as.matrix()
load("~/GitHub/data/DH_grundlagen/12/fuersitzung.Rdata.RData")
#knitr::opts_chunk$set(echo = TRUE)
library(knitr)
library(DT)
dtm_tfidf <- text_df %>%
unnest_tokens(word, text, token="words", to_lower = TRUE) %>% # wieder in Token auf "Wort"-Basis aufsplitten und alles klein setzen
group_by(id, word) %>% # nach Werk-ID und Wort gruppieren
mutate(count = n()) %>% # dank Gruppierung wird jedes Wort pro Werk gezählt und in "count"-Variable geschrieben
ungroup() %>%
mutate(id = paste(autor, id)) %>%
select(word, id, count) %>% # wir brauchen nur noch diese Variablen
cast_dtm(id, word, count, weighting = tm::weightTfIdf) %>%
as.matrix() %>%
as.tibble()
library(knitr)
library(tidyverse)
library(tidytext)
library(tm)
library(stringr)
library(stringi)
library(gutenbergr)
library(quanteda)
dtm_tfidf <- text_df %>%
unnest_tokens(word, text, token="words", to_lower = TRUE) %>% # wieder in Token auf "Wort"-Basis aufsplitten und alles klein setzen
group_by(id, word) %>% # nach Werk-ID und Wort gruppieren
mutate(count = n()) %>% # dank Gruppierung wird jedes Wort pro Werk gezählt und in "count"-Variable geschrieben
ungroup() %>%
mutate(id = paste(autor, id)) %>%
select(word, id, count) %>% # wir brauchen nur noch diese Variablen
cast_dtm(id, word, count, weighting = tm::weightTfIdf) %>%
as.matrix() %>%
as.tibble()
dtm_tfidf_small <- dtm_tfidf %>%
as.dfm %>%
tidy() %>%
filter(count >= ((max(count)) / 100)*20) %>%
cast_sparse(document, term, count) %>%
as.matrix() %>%
data.frame()
head(dtm_tfidf_small)
dtm_tfidf <- text_df %>%
unnest_tokens(word, text, token="words", to_lower = TRUE) %>% # wieder in Token auf "Wort"-Basis aufsplitten und alles klein setzen
group_by(id, word) %>% # nach Werk-ID und Wort gruppieren
mutate(count = n()) %>% # dank Gruppierung wird jedes Wort pro Werk gezählt und in "count"-Variable geschrieben
ungroup() %>%
mutate(id = paste(autor, id)) %>%
select(word, id, count) %>% # wir brauchen nur noch diese Variablen
cast_dtm(id, word, count, weighting = tm::weightTfIdf) %>%
tidy()
head(dtm_tfidf)
dtm_tfidf <- text_df %>%
unnest_tokens(word, text, token="words", to_lower = TRUE) %>% # wieder in Token auf "Wort"-Basis aufsplitten und alles klein setzen
group_by(id, word) %>% # nach Werk-ID und Wort gruppieren
mutate(count = n()) %>% # dank Gruppierung wird jedes Wort pro Werk gezählt und in "count"-Variable geschrieben
ungroup() %>%
mutate(id = paste(autor, id)) %>%
select(word, id, count) %>% # wir brauchen nur noch diese Variablen
cast_dtm(id, word, count, weighting = tm::weightTfIdf) %>%
tidy()
head(dtm_tfidf)
dtm_tfidf_small <- dtm_tfidf %>%
filter(count >= (max(count) / 100) * 10 ) %>% # count muss mindestens 10% des Maximums sein
cast_dtm(document, term, count) # Rückumwandlung in DTM
pca_tfidf <- prcomp(data.frame(as.matrix(dtm_tfidf_small)))
summary(pca_tfidf)
head(pca_tfidf$rotation)
dtm_tfidf_small
sort(pca_tfidfrotation[,1])
sort(pca_tfidf$rotation[,1])
topics <- pca_tfidf$rotation %>%
tidy()
topics
head(topics)
plot(pca_tfidf)
class(topics)
tidy(topics)
topics <- pca_tfidf$rotation %>%
as.tibble %>%
tidy()
topics
topics <- pca_tfidf$rotation %>%
as.tibble #%>%
topics
row.names(pca_tfidf$rotation)
sort(pca_tfidf$rotation[,1])
sort(pca_tfidf$rotation[,2])
sort(abs(pca_tfidf$rotation[,2]))
sort(abs(pca_tfidf$rotation[,1]))
diplot(pca_tfidf)
biplot(pca_tfidf)
sort(abs(pca_tfidf$rotation[,3]))
names(pca_tfidf)
library(stylo)
stylo(gui=FALSE, frequencies = dtm_tfidf_small, analysis.type="PCA")
class(dtm_tfidf_small)
stylo(gui=FALSE, frequencies = data.frame(as.matrix(dtm_tfidf_small)), analysis.type="PCA")
stylo(gui=FALSE, frequencies = data.frame(as.matrix(dtm_tfidf_small)), analysis.type="PCA", distance.measure="delta")
sort(abs(pca_tfidf$rotation[,4]))
sort(abs(pca_tfidf$rotation[,5]))
sort(abs(pca_tfidf$rotation[,6]))
library(SpaDES)
library(data.table)
whereSpaDES <- find.package(package  = "SpaDES")
whereSamples <- system.file('sampleModules', package = 'SpaDES')
file.path(whereSamples, 'caribouMovement', 'caribouMovement.R') %>%
file.edit()
library(dplyr)
whereSpaDES <- find.package(package  = "SpaDES")
whereSamples <- system.file('sampleModules', package = 'SpaDES')
file.path(whereSamples, 'caribouMovement', 'caribouMovement.R') %>%
file.edit()
moduleDir <- file.path(tempdir(), 'SpaDES_modules')
# download all necessary modules
downloadModule('LCC2005', path = moduleDir, data = TRUE)
# look at module or helper .Rmd file
openModules('LCC2005', path = moduleDir)
shiny::runApp("~/GitHub/LandwebApp/")
library("tm")
library("openNLP")
install.packages("openNLP")
library(openNLP)
library("tm")
library("stringi")
library("topicmodels")
install.packages("topicmodels")
install.packages("topicmodels", dependencies=TRUE)
install.packages("topicmodels", dependencies=TRUE)
install.packages("corpus.JSS.papers")
load("~/GitHub/data/DH_grundlagen/12/fuersitzung.Rdata.RData")
text_df[,1]
text_df[1,]
class(text_df)
install.packages("cleanNLP")
library(cleanNLP)
cnlp_init_udpipe()
install.packages("udpipe")
cnlp_init_udpipe()
cnlp_init_udpipe()
annotations <- text_df %>%
cnlp_get_token(text)
library(tidyverse)
annotations <- text_df %>%
cnlp_get_token(text)
library(cleanNLP)
cnlp_init_udpipe()
annotations <- text_df %>%
cnlp_get_token(text)
library(cleanNLP)
detach("package:tidyverse", unload=TRUE)
detach("package:cleanNLP", unload=TRUE)
library(tidyverse)
library(cleanNLP)
detach("package:cleanNLP", unload=TRUE)
detach("package:tidyverse", unload=TRUE)
annotations <- text_df %>%
cnlp_get_token(text)
library(dplyr)
library(cleanNLP)
cnlp_init_udpipe()
names(text_df)
annotations <- text_df %>%
annotate() %>%
cnlp_get_token()
library(SpaDES)  ## should automatically download all packages in the SpaDES family and their dependencies
## decide where you're working
mainDir <- '~/GitHub/R_MaDisBe/' # SET YOUR MAIN DIRECTORY HERE.
setPaths(cachePath = "cache",
modulePath = "modules",
inputPath = "../data/inputs",
outputPath = "../data/outputs")
library(SpaDES.core)
library(dplyr)
library(igraph)
envir <- make_lattice(length=20, dim=2, directed=FALSE)
envir
get.adjacency(envir)
View(get.adjacency(envir))
View(as.matrix(get_adjacency(envir)))
View(as.matrix(get.adjacency(envir)))
class(get.adjacency(envir))
get.adjacency(envir)[2,3]
get.adjacency(envir)[2,4]
class(get.adjacency(envir))
matrix(c(3,4,5,2), ncol=2)
matrix(c(3,4,5,2), ncol=2)-3
c(1,2,3,4) * c(3,2,4,5)
matrix(0, length=2^2, ncol=2)
matrix(rep(0, 2^2), ncol=2)
contributors()
-(3,1)
outer(c(1,2), c(2,19), -)
outer(c(1,2), c(2,19), -)
outer(c(1,2), c(2,19), FUN= -)
outer(c(1,2), c(2,19), FUN= log())
outer(c(1,2), c(2,19), FUN="-")
library(dplyr)
matrix(length=no_agents^2, ncol=2) %>% outer(sim$opinions, sim$opinions, FUN="-")
matrix(length=2^2, ncol=2) %>% outer(c(1,2), c(1,2), FUN="-")
matrix(length=2^2, ncol=2)
matrix(nrow=2, ncol=2) %>% outer(c(1,2), c(1,2), FUN="-")
outer(c(1,2), c(1,2), FUN="-")
test <- matrix(nrow=2, ncol=2)
test <- outer(c(1,2), c(1,2), FUN="-")
test
c(1,2) * c(1,2)
test > 4
test > 0
(test > 0) * c(1,2,3,4)
(test > 0) *%* c(1,2,3,4)
(test > 0) %*% c(1,2,3,4)
(test > 0) * c(1,2,3,4)
test * c(1,2,3,4)
test
mapply(rep, 1:4, 4:1)
mapply(rep, 1:4, 4:1, simplify=T)
mapply(rep, 1:4, 4:1, SIMPLIFY=T)
mapply(rep, 1:4, 4:1)
test
test > 0 %*% matrix(c(3,4,5,6), ncol=2)
matrix(c(3,4,5,6), ncol=2)
test > 0
test > 0 * matrix(c(3,4,5,6), ncol=2)
(test > 0) * matrix(c(3,4,5,6), ncol=2)
library(igraph)
make_lattice(20, dim=2)
make_lattice(20, dim=2)
test <- make_lattice(20, dim=2)
adj <- get.adjacency(test)
adj
mean(degree(adj))
install.packages("tidygraph")
library(tidygraph)
make_ring(10)
create_ring()
create_ring(10)
fuck <- create_ring()
fuck <- create_ring(10)
activate(fuck, edges)
fuck[1,]
names(fuck)
fuck
class(fuck)
fuck %>% activate(edges) %>% filter(from == 1)
fuck %>% activate(nodes)
fuck %>% activate(nodes) %>% names()
fuck %>% activate(nodes) %>% View()
create_lattice(2)
create_lattice(100, 2)
class(create_ring(10))
library(SpaDES.core)
text <- create_ring(10)
library(dplyr)
text %>% activate(edges) %>% mutate(neighborhood = local_members(mindist = 1))
text %>% activate(nodes) %>% mutate(neighborhood = local_members(mindist = 1))
test <- text %>% activate(nodes) %>% mutate(neighborhood = local_members(mindist = 1))
test
test$neighborhood
test %>% active(neighborhood)
test %>% active(nodes)$neighborhood
test %>% active(nodes) %>% View()
test
test <- text %>% activate(nodes) %>% mutate(neighborhood = local_members(mindist = 1))
test
test %>% activate(nodes)
test %>% activate(nodes) %>% activate(neighborhood)
create_notable(
'
chvatal
'
) %>%
activate(nodes) %>%
mutate(neighborhood = local_members(mindist = 1))
create_notable(chvatal) %>%
activate(nodes) %>%
mutate(neighborhood = local_members(mindist = 1))
create_notable(10) %>%
activate(nodes) %>%
mutate(neighborhood = local_members(mindist = 1))
test <- text %>% activate(nodes) %>% mutate(neighborhood = local_members(mindist = 1))
test %>% mutate(nbh_size = local_size(mindist = 1))
test %>% activate(nodes)
test %>% activate(nodes) %>% summary()
test %>% activate(nodes) %>% as.vector()
test %>% activate(nodes) %>% select(node)
test %>% activate(nodes) %>% names()
test
library(SpaDES)  ## should automatically download all packages in the SpaDES family and their dependencies
## decide where you're working
mainDir <- '~/GitHub/R_MaDisBe/simulation' # SET YOUR MAIN DIRECTORY HERE.
setPaths(cachePath = "cache",
modulePath = "modules",
inputPath = "../data/inputs",
outputPath = "../data/outputs")
modules <- list("basic_setup", "lattice", "hegselmann_krause", "data_collection")
times <- list(start = 0.0, end = 1000)
parameters <- list(
basic_setup = list(
no_agents = 100
),
lattice = list(
directed = FALSE
),
hegselmann_krause = list(
epsilon = 0.1
)
)
paths <- getPaths()
SIM <- simInit(times = times, params = parameters, modules = modules, paths = paths)
setwd('~/GitHub/R_MaDisBe/simulation')
SIM <- simInit(times = times, params = parameters, modules = modules, paths = paths)
SIM <- simInit(times = times, params = parameters, modules = modules, paths = paths, debug=TRUE)
SIM <- simInit(times = times, params = parameters, modules = modules, paths = paths)
SIM <- simInit(times = times, params = parameters, modules = modules, paths = paths)
SIM <- simInit(times = times, params = parameters, modules = modules, paths = paths)
SIM <- simInit(times = times, params = parameters, modules = modules, paths = paths)
SIM <- simInit(times = times, params = parameters, modules = modules, paths = paths)
SIM <- simInit(times = times, params = parameters, modules = modules, paths = paths)
SIM <- simInit(times = times, params = parameters, modules = modules, paths = paths)
SIM <- simInit(times = times, params = parameters, modules = modules, paths = paths)
traceback()
SIM <- simInit(times = times, params = parameters, modules = modules, paths = paths)
traceback()
traceback()
SIM <- simInit(times = times, params = parameters, modules = modules, paths = paths)
traceback
traceback()
SIM <- simInit(times = times, params = parameters, modules = modules, paths = paths)
traceback()
SIM <- simInit(times = times, params = parameters, modules = modules, paths = paths)
SIM <- simInit(times = times, params = parameters, modules = modules, paths = paths)
out <- spades(SIM, .plotInitialTime = NA) # parameter means plotting is off (faster)
SIM <- simInit(times = times, params = parameters, modules = modules, paths = paths)
out <- spades(SIM, .plotInitialTime = NA) # parameter means plotting is off (faster)
SIM <- simInit(times = times, params = parameters, modules = modules, paths = paths)
out <- spades(SIM, .plotInitialTime = NA) # parameter means plotting is off (faster)
SIM <- simInit(times = times, params = parameters, modules = modules, paths = paths)
out <- spades(SIM, .plotInitialTime = NA) # parameter means plotting is off (faster)
traceback()
out <- spades(SIM)
traceback()
out <- spades(SIM, debug=TRUE)
return(invisible(sim))
SIM <- simInit(times = times, params = parameters, modules = modules, paths = paths)
out <- spades(SIM, debug=TRUE)
sqrt(100)
sqrt(39)
floor(sqrt(100)/2)*ceiling(sqrt(100)/2)
floor(100/2)*ceiling(100/2)
sqrt(floor(100/2)*ceiling(100/2))
sqrt(100)
sqrt(100)*sqrt(100)
sqrt(100)*sqrt(39)
sqrt(39)*sqrt(39)
ceiling(sqrt(39))*floor(sqrt(39))
ceiling(sqrt(39))
floor(sqrt(39))
SIM <- simInit(times = times, params = parameters, modules = modules, paths = paths)
out <- spades(SIM)
SIM <- simInit(times = times, params = parameters, modules = modules, paths = paths)
out <- spades(SIM)
SIM <- simInit(times = times, params = parameters, modules = modules, paths = paths)
out <- spades(SIM)
SIM <- simInit(times = times, params = parameters, modules = modules, paths = paths)
out <- spades(SIM)
SIM <- simInit(times = times, params = parameters, modules = modules, paths = paths)
out <- spades(SIM)
